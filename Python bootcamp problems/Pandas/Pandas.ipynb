{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PANDAS PRACTICE QUESTION \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Loading a csv in Pandas\n",
    "Description\n",
    "Create a dataframe from the file ‘marks.csv’ and print the contents of the dataframe. \n",
    "Open the file from the link above and inspect the required elements in the file (header, separator, etc.). \n",
    "If the top row is a regular entry, do not load it as the column header. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0        1            2   3   4   5\n",
      "0    1   Akshay  Mathematics  50  40  80\n",
      "1    2   Mahima      English  40  33  83\n",
      "2    3    Vikas  Mathematics  50  42  84\n",
      "3    4  Abhinav      English  40  31  78\n",
      "4    5   Mahima      Science  50  40  80\n",
      "5    6   Akshay      Science  50  49  98\n",
      "6    7  Abhinav  Mathematics  50  47  94\n",
      "7    8    Vikas      Science  50  40  80\n",
      "8    9  Abhinav      Science  50  47  94\n",
      "9   10    Vikas      English  40  39  98\n",
      "10  11   Akshay      English  40  35  88\n",
      "11  12   Mahima  Mathematics  50  43  86\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The file is stored at the following path:\n",
    "# 'https://media-doselect.s3.amazonaws.com/generic/A08MajL8qN4rq72EpVJbAP1Rw/marks_1.csv'\n",
    "# Provide your answer below\n",
    "df = pd.read_csv(\"https://media-doselect.s3.amazonaws.com/generic/A08MajL8qN4rq72EpVJbAP1Rw/marks_1.csv\",delimiter=\"|\",header=None)# Write your answer here\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Using the file ‘marks.csv’, create a dataframe as shown below.\n",
    "\n",
    "You must be able make the first column of the file as the index and name it 'S.No.'. Also, the columns must be renamed as shown in the image. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name      Subject  Maximum Marks  Marks Obtained  Percentage\n",
      "S.No.                                                                 \n",
      "1       Akshay  Mathematics             50              40          80\n",
      "2       Mahima      English             40              33          83\n",
      "3        Vikas  Mathematics             50              42          84\n",
      "4      Abhinav      English             40              31          78\n",
      "5       Mahima      Science             50              40          80\n",
      "6       Akshay      Science             50              49          98\n",
      "7      Abhinav  Mathematics             50              47          94\n",
      "8        Vikas      Science             50              40          80\n",
      "9      Abhinav      Science             50              47          94\n",
      "10       Vikas      English             40              39          98\n",
      "11      Akshay      English             40              35          88\n",
      "12      Mahima  Mathematics             50              43          86\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The file is stored at the following path:\n",
    "# 'https://media-doselect.s3.amazonaws.com/generic/A08MajL8qN4rq72EpVJbAP1Rw/marks_1.csv'\n",
    "# Provide your answer below\n",
    "df = pd.read_csv(\"marks_1.csv\",sep=\"|\",header=None,index_col=0)# Write your answer here\n",
    "df.columns = [\"Name\",\"Subject\",\"Maximum Marks\",\"Marks Obtained\",\"Percentage\"]\n",
    "df.index.name=\"S.No.\"\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hierarchical Indexing\n",
    "Description\n",
    "You are provided with the dataset of a company which has offices across three cities - Mumbai, Bangalore and New Delhi. The dataset contains the rating (out of 5) of all the employees from different departments (Finance, HR, Marketing and Sales). \n",
    "\n",
    "Create a hierarchical index based on two columns: Office and Department\n",
    "\n",
    "Print the first 5 rows as the output. Refer to the image below for your reference.\n",
    "\n",
    "Note: You should not sort or modify values in other columns of the dataframe. Use sort_index(inplace=True) to club the same locations together. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ID  Rating\n",
      "Office    Department               \n",
      "Bangalore Finance     U2F53     2.7\n",
      "          Finance     U1F53     3.7\n",
      "          Finance     U1F28     3.2\n",
      "          Finance     U1F15     3.3\n",
      "          Finance     U1F14     2.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The file is stored at the following path:\n",
    "# 'https://media-doselect.s3.amazonaws.com/generic/NMgEjwkAEGGQZBoNYGr9Ld7w0/rating.csv'\n",
    "df = pd.read_csv('https://media-doselect.s3.amazonaws.com/generic/NMgEjwkAEGGQZBoNYGr9Ld7w0/rating.csv',index_col=[2,1])\n",
    "\n",
    "# Provide your answer below\n",
    "df.sort_index(inplace=True)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Description\n",
    "Given a dataframe 'df' use the following commands and analyse the result.\n",
    "describe() \n",
    "columns\n",
    "shape\n",
    "Execution Time Limit \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                X           Y        FFMC         DMC          DC         ISI  \\\n",
      "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
      "mean     4.669246    4.299807   90.644681  110.872340  547.940039    9.021663   \n",
      "std      2.313778    1.229900    5.520111   64.046482  248.066192    4.559477   \n",
      "min      1.000000    2.000000   18.700000    1.100000    7.900000    0.000000   \n",
      "25%      3.000000    4.000000   90.200000   68.600000  437.700000    6.500000   \n",
      "50%      4.000000    4.000000   91.600000  108.300000  664.200000    8.400000   \n",
      "75%      7.000000    5.000000   92.900000  142.400000  713.900000   10.800000   \n",
      "max      9.000000    9.000000   96.200000  291.300000  860.600000   56.100000   \n",
      "\n",
      "             temp          RH        wind        rain         area  \n",
      "count  517.000000  517.000000  517.000000  517.000000   517.000000  \n",
      "mean    18.889168   44.288201    4.017602    0.021663    12.847292  \n",
      "std      5.806625   16.317469    1.791653    0.295959    63.655818  \n",
      "min      2.200000   15.000000    0.400000    0.000000     0.000000  \n",
      "25%     15.500000   33.000000    2.700000    0.000000     0.000000  \n",
      "50%     19.300000   42.000000    4.000000    0.000000     0.520000  \n",
      "75%     22.800000   53.000000    4.900000    0.000000     6.570000  \n",
      "max     33.300000  100.000000    9.400000    6.400000  1090.840000  \n",
      "Index(['X', 'Y', 'month', 'day', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH',\n",
      "       'wind', 'rain', 'area'],\n",
      "      dtype='object')\n",
      "(517, 13)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df = pd.read_csv('https://query.data.world/s/vBDCsoHCytUSLKkLvq851k2b8JOCkF')\n",
    "print(df.describe())#Type your code for describing the dataset)\n",
    "print(df.columns)#Type your code for printing the columns of the dataset)\n",
    "print(df.shape)#Type your code for printing the shape of the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Selecting Columns of a Dataframe\n",
    "Description\n",
    "Print out the columns 'month', 'day', 'temp', 'area' from the dataframe 'df'. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  day  temp  area\n",
      "0    mar  fri   8.2   0.0\n",
      "1    oct  tue  18.0   0.0\n",
      "2    oct  sat  14.6   0.0\n",
      "3    mar  fri   8.3   0.0\n",
      "4    mar  sun  11.4   0.0\n",
      "5    aug  sun  22.2   0.0\n",
      "6    aug  mon  24.1   0.0\n",
      "7    aug  mon   8.0   0.0\n",
      "8    sep  tue  13.1   0.0\n",
      "9    sep  sat  22.8   0.0\n",
      "10   sep  sat  17.8   0.0\n",
      "11   sep  sat  19.3   0.0\n",
      "12   aug  fri  17.0   0.0\n",
      "13   sep  mon  21.3   0.0\n",
      "14   sep  wed  26.4   0.0\n",
      "15   sep  fri  22.9   0.0\n",
      "16   mar  sat  15.1   0.0\n",
      "17   oct  mon  16.7   0.0\n",
      "18   mar  wed  15.9   0.0\n",
      "19   apr  sat   9.3   0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df = pd.read_csv('https://query.data.world/s/vBDCsoHCytUSLKkLvq851k2b8JOCkF')\n",
    "df_2 = df[['month', 'day' , 'temp' , 'area']]#Type your code for selecting columns 'month', 'day' , 'temp' , 'area'\n",
    "print(df_2.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Description\n",
    "Print only the even numbers of rows of the dataframe 'df'.\n",
    "\n",
    "Note: Don't include the row indexed zero.\n",
    "Execution Time Limit \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X  Y month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  area\n",
      "2   7  4   oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.0\n",
      "4   8  6   mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.0\n",
      "6   8  6   aug  mon  92.3   88.9  495.6   8.5  24.1  27   3.1   0.0   0.0\n",
      "8   8  6   sep  tue  91.0  129.5  692.6   7.0  13.1  63   5.4   0.0   0.0\n",
      "10  7  5   sep  sat  92.5   88.0  698.6   7.1  17.8  51   7.2   0.0   0.0\n",
      "12  6  5   aug  fri  63.5   70.8  665.3   0.8  17.0  72   6.7   0.0   0.0\n",
      "14  6  5   sep  wed  92.9  133.3  699.6   9.2  26.4  21   4.5   0.0   0.0\n",
      "16  5  5   mar  sat  91.7   35.8   80.8   7.8  15.1  27   5.4   0.0   0.0\n",
      "18  6  4   mar  wed  89.2   27.9   70.8   6.3  15.9  35   4.0   0.0   0.0\n",
      "20  6  4   sep  tue  91.0  129.5  692.6   7.0  18.3  40   2.7   0.0   0.0\n",
      "22  7  4   jun  sun  94.3   96.3  200.0  56.1  21.0  44   4.5   0.0   0.0\n",
      "24  7  4   aug  sat  93.5  139.4  594.2  20.3  23.7  32   5.8   0.0   0.0\n",
      "26  7  4   sep  fri  92.4  117.9  668.0  12.2  19.0  34   5.8   0.0   0.0\n",
      "28  6  3   sep  sat  93.4  145.4  721.4   8.1  30.2  24   2.7   0.0   0.0\n",
      "30  6  3   sep  fri  94.3   85.1  692.3  15.9  25.4  24   3.6   0.0   0.0\n",
      "32  6  3   sep  fri  88.6   69.7  706.8   5.8  20.6  37   1.8   0.0   0.0\n",
      "34  6  3   sep  mon  91.8   78.5  724.3   9.2  21.2  32   2.7   0.0   0.0\n",
      "36  6  3   oct  tue  90.6   35.4  669.1   6.7  21.7  24   4.5   0.0   0.0\n",
      "38  7  3   oct  sat  90.6   43.7  686.9   6.7  17.8  27   4.0   0.0   0.0\n",
      "40  4  4   jul  tue  79.5   60.6  366.7   1.5  23.3  37   3.1   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df = pd.read_csv('https://query.data.world/s/vBDCsoHCytUSLKkLvq851k2b8JOCkF')\n",
    "df_2 = df[2::2]#Type your code here for indexing the dataframe\n",
    "print(df_2.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Applying Conditions on Dataframes\n",
    "Description\n",
    "Print all the columns and the rows where 'area' is greater than 0, 'wind' is greater than 1 and the 'temp' is greater than 15. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     X  Y month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  area\n",
      "138  9  9   jul  tue  85.8   48.3  313.4   3.9  18.0  42   2.7   0.0  0.36\n",
      "139  1  4   sep  tue  91.0  129.5  692.6   7.0  21.7  38   2.2   0.0  0.43\n",
      "140  2  5   sep  mon  90.9  126.5  686.5   7.0  21.9  39   1.8   0.0  0.47\n",
      "141  1  2   aug  wed  95.5   99.9  513.3  13.2  23.3  31   4.5   0.0  0.55\n",
      "142  8  6   aug  fri  90.1  108.0  529.8  12.5  21.2  51   8.9   0.0  0.61\n",
      "143  1  2   jul  sat  90.0   51.3  296.3   8.7  16.6  53   5.4   0.0  0.71\n",
      "144  2  5   aug  wed  95.5   99.9  513.3  13.2  23.8  32   5.4   0.0  0.77\n",
      "145  6  5   aug  thu  95.2  131.7  578.8  10.4  27.4  22   4.0   0.0  0.90\n",
      "147  8  3   sep  tue  84.4   73.4  671.9   3.2  24.2  28   3.6   0.0  0.96\n",
      "148  2  2   aug  tue  94.8  108.3  647.1  17.0  17.4  43   6.7   0.0  1.07\n",
      "149  8  6   sep  thu  93.7   80.9  685.2  17.9  23.7  25   4.5   0.0  1.12\n",
      "150  6  5   jun  fri  92.5   56.4  433.3   7.1  23.2  39   5.4   0.0  1.19\n",
      "151  9  9   jul  sun  90.1   68.6  355.2   7.2  24.8  29   2.2   0.0  1.36\n",
      "152  3  4   jul  sat  90.1   51.2  424.1   6.2  24.6  43   1.8   0.0  1.43\n",
      "153  5  4   sep  fri  94.3   85.1  692.3  15.9  20.1  47   4.9   0.0  1.46\n",
      "154  1  5   sep  sat  93.4  145.4  721.4   8.1  29.6  27   2.7   0.0  1.46\n",
      "155  7  4   aug  sun  94.8  108.3  647.1  17.0  16.4  47   1.3   0.0  1.56\n",
      "156  2  4   sep  sat  93.4  145.4  721.4   8.1  28.6  27   2.2   0.0  1.61\n",
      "157  2  2   aug  wed  92.1  111.2  654.1   9.6  18.4  45   3.6   0.0  1.63\n",
      "158  2  4   aug  wed  92.1  111.2  654.1   9.6  20.5  35   4.0   0.0  1.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df = pd.read_csv('https://query.data.world/s/vBDCsoHCytUSLKkLvq851k2b8JOCkF')\n",
    "df_2 = df[(df[\"area\"]>0)&(df[\"wind\"]>1)&(df[\"temp\"]>15)]#Type your code here.\n",
    "print(df_2.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X       517 non-null    int64  \n",
      " 1   Y       517 non-null    int64  \n",
      " 2   month   517 non-null    object \n",
      " 3   day     517 non-null    object \n",
      " 4   FFMC    517 non-null    float64\n",
      " 5   DMC     517 non-null    float64\n",
      " 6   DC      517 non-null    float64\n",
      " 7   ISI     517 non-null    float64\n",
      " 8   temp    517 non-null    float64\n",
      " 9   RH      517 non-null    int64  \n",
      " 10  wind    517 non-null    float64\n",
      " 11  rain    517 non-null    float64\n",
      " 12  area    517 non-null    float64\n",
      "dtypes: float64(8), int64(3), object(2)\n",
      "memory usage: 52.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Employee Training\n",
    "Description\n",
    "You are provided with the dataset of a company which has offices across three cities - Mumbai, Bangalore and New Delhi. The dataset contains the rating (out of 5) of all the employees from different departments (Finance, HR, Marketing and Sales). \n",
    "\n",
    "\n",
    "\n",
    "The company has come up with a new policy that any individual with a rating equal to or below 3.5 needs to attend a training. Using dataframes, load the dataset and then derive the column ‘Training’ which shows ‘Yes’ for people who require training and ‘No’ for those who do not.\n",
    "\n",
    "Print the first 5 rows as the output. Refer to the image below for your reference.\n",
    "\n",
    "Note: You should not sort or modify values in other columns of the dataframe. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID Department     Office  Rating Training\n",
      "0  U2F26    Finance  New Delhi     3.4      Yes\n",
      "1  U2M61  Marketing  New Delhi     3.9       No\n",
      "2  U1S15      Sales  New Delhi     2.8      Yes\n",
      "3  U1H87         HR     Mumbai     2.1      Yes\n",
      "4  U1S51      Sales  New Delhi     4.6       No\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The file is stored at the following path:\n",
    "# 'https://media-doselect.s3.amazonaws.com/generic/NMgEjwkAEGGQZBoNYGr9Ld7w0/rating.csv'\n",
    "df = pd.read_csv('https://media-doselect.s3.amazonaws.com/generic/NMgEjwkAEGGQZBoNYGr9Ld7w0/rating.csv')\n",
    "df[\"Training\"] = df.Rating.apply(lambda x: \"Yes\" if x<=3.5 else \"No\")\n",
    "# Provide your answer below\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Training</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Department</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Finance</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing</th>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Training    No  Yes\n",
       "Department         \n",
       "Finance     67   67\n",
       "HR          75   56\n",
       "Marketing   64   74\n",
       "Sales       64   66"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df[\"Department\"],df[\"Training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rating' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarketing\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;28mlen\u001b[39m(\u001b[43mrating\u001b[49m[(rating[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (rating[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i)]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(rating[rating[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rating' is not defined"
     ]
    }
   ],
   "source": [
    "for i in ['Finance', 'HR', 'Sales', 'Marketing']:\n",
    "    print(i, len(rating[(rating['Training'] == 'No') & (rating['Department'] == i)]) / len(rating[rating['Department'] == i]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X  Y month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain   area\n",
       "0    7  5   mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00\n",
       "1    7  4   oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00\n",
       "2    7  4   oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00\n",
       "3    8  6   mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00\n",
       "4    8  6   mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00\n",
       "..  .. ..   ...  ...   ...    ...    ...   ...   ...  ..   ...   ...    ...\n",
       "512  4  3   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44\n",
       "513  2  4   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29\n",
       "514  7  4   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16\n",
       "515  1  4   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00\n",
       "516  6  3   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00\n",
       "\n",
       "[517 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Dataframe grouping\n",
    "Description\n",
    "Group the dataframe 'df' by 'month' and 'day' and find the mean value for column 'rain' and 'wind'. \"\"\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://query.data.world/s/vBDCsoHCytUSLKkLvq851k2b8JOCkF')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               rain      wind\n",
      "month day                    \n",
      "apr   fri  0.000000  3.100000\n",
      "      mon  0.000000  3.100000\n",
      "      sat  0.000000  4.500000\n",
      "      sun  0.000000  5.666667\n",
      "      thu  0.000000  5.800000\n",
      "      wed  0.000000  2.700000\n",
      "aug   fri  0.066667  4.766667\n",
      "      mon  0.000000  2.873333\n",
      "      sat  0.000000  4.310345\n",
      "      sun  0.025000  4.417500\n",
      "      thu  0.000000  3.503846\n",
      "      tue  0.300000  4.567857\n",
      "      wed  0.000000  3.520000\n",
      "dec   fri  0.000000  4.900000\n",
      "      mon  0.000000  8.500000\n",
      "      sun  0.000000  8.500000\n",
      "      thu  0.000000  4.900000\n",
      "      tue  0.000000  8.500000\n",
      "      wed  0.000000  8.000000\n",
      "feb   fri  0.000000  4.820000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df = pd.read_csv('https://query.data.world/s/vBDCsoHCytUSLKkLvq851k2b8JOCkF')\n",
    "#Type your groupby command here\n",
    "col =[\"rain\",\"wind\"]\n",
    "df_1 = df.groupby([\"month\",\"day\"])[col].mean()    #Type your code to find the mean of columns 'rain' and 'wind'\n",
    "print(df_1.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dataframes Merge\n",
    "Description\n",
    "Perform an inner merge on two data frames df_1 and df_2 on  'unique_id' and print the combined dataframe.\n",
    "Execution Time Limit\n",
    "20 seconds \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           name                     address              city  \\\n",
      "0     arnie morton's of chicago   \"435 s. la cienega blvd.\"     \"los angeles\"   \n",
      "1                    art's deli       \"12224 ventura blvd.\"     \"studio city\"   \n",
      "2                 bel-air hotel      \"701 stone canyon rd.\"         \"bel air\"   \n",
      "3                    cafe bizou       \"14016 ventura blvd.\"    \"sherman oaks\"   \n",
      "4                     campanile       \"624 s. la brea ave.\"     \"los angeles\"   \n",
      "5               chinois on main             \"2709 main st.\"    \"santa monica\"   \n",
      "6                        citrus         \"6703 melrose ave.\"     \"los angeles\"   \n",
      "7           fenix at the argyle         \"8358 sunset blvd.\"    \"w. hollywood\"   \n",
      "8                       granita       \"23725 w. malibu rd.\"          \"malibu\"   \n",
      "9                    grill  the           \"9560 dayton way\"   \"beverly hills\"   \n",
      "10                        katsu       \"1972 hillhurst ave.\"       \"los feliz\"   \n",
      "11                  l'orangerie   \"903 n. la cienega blvd.\"    \"w. hollywood\"   \n",
      "12  le chardonnay (los angeles)         \"8284 melrose ave.\"     \"los angeles\"   \n",
      "13               locanda veneta         \"8638 w. third st.\"     \"los angeles\"   \n",
      "14                    matsuhisa   \"129 n. la cienega blvd.\"   \"beverly hills\"   \n",
      "15      palm  the (los angeles)   \"9001 santa monica blvd.\"    \"w. hollywood\"   \n",
      "16                       patina         \"5955 melrose ave.\"     \"los angeles\"   \n",
      "17        philippe the original       \"1001 n. alameda st.\"       \"chinatown\"   \n",
      "18                 pinot bistro       \"12969 ventura blvd.\"     \"studio city\"   \n",
      "19            rex il ristorante          \"617 s. olive st.\"     \"los angeles\"   \n",
      "\n",
      "                      cuisine unique_id                     name_2  \\\n",
      "0               \"steakhouses\"       '0'  arnie morton's of chicago   \n",
      "1                     \"delis\"       '1'         art's delicatessen   \n",
      "2               \"californian\"       '2'              hotel bel-air   \n",
      "3             \"french bistro\"       '3'                 cafe bizou   \n",
      "4               \"californian\"       '4'                  campanile   \n",
      "5          \"pacific new wave\"       '5'            chinois on main   \n",
      "6               \"californian\"       '6'                     citrus   \n",
      "7              \"french (new)\"       '7'                      fenix   \n",
      "8               \"californian\"       '8'                    granita   \n",
      "9    \"american (traditional)\"       '9'         grill on the alley   \n",
      "10                 \"japanese\"      '10'           restaurant katsu   \n",
      "11         \"french (classic)\"      '11'                l'orangerie   \n",
      "12            \"french bistro\"      '12'              le chardonnay   \n",
      "13                  \"italian\"      '13'             locanda veneta   \n",
      "14                  \"seafood\"      '14'                  matsuhisa   \n",
      "15              \"steakhouses\"      '15'                   the palm   \n",
      "16              \"californian\"      '16'                     patina   \n",
      "17               \"cafeterias\"      '17'    philippe's the original   \n",
      "18            \"french bistro\"      '18'               pinot bistro   \n",
      "19     \"nuova cucina italian\"      '19'          rex il ristorante   \n",
      "\n",
      "                     address_2            city_2       cuisine_2  \n",
      "0     \"435 s. la cienega blv.\"     \"los angeles\"      \"american\"  \n",
      "1        \"12224 ventura blvd.\"     \"studio city\"      \"american\"  \n",
      "2       \"701 stone canyon rd.\"         \"bel air\"   \"californian\"  \n",
      "3        \"14016 ventura blvd.\"    \"sherman oaks\"        \"french\"  \n",
      "4        \"624 s. la brea ave.\"     \"los angeles\"      \"american\"  \n",
      "5              \"2709 main st.\"    \"santa monica\"        \"french\"  \n",
      "6          \"6703 melrose ave.\"     \"los angeles\"   \"californian\"  \n",
      "7     \"8358 sunset blvd. west\"       \"hollywood\"      \"american\"  \n",
      "8        \"23725 w. malibu rd.\"          \"malibu\"   \"californian\"  \n",
      "9            \"9560 dayton way\"     \"los angeles\"      \"american\"  \n",
      "10    \"1972 n. hillhurst ave.\"     \"los angeles\"         \"asian\"  \n",
      "11   \"903 n. la cienega blvd.\"     \"los angeles\"        \"french\"  \n",
      "12         \"8284 melrose ave.\"     \"los angeles\"        \"french\"  \n",
      "13                   \"3rd st.\"     \"los angeles\"       \"italian\"  \n",
      "14   \"129 n. la cienega blvd.\"   \"beverly hills\"         \"asian\"  \n",
      "15   \"9001 santa monica blvd.\"     \"los angeles\"      \"american\"  \n",
      "16         \"5955 melrose ave.\"     \"los angeles\"   \"californian\"  \n",
      "17       \"1001 n. alameda st.\"     \"los angeles\"      \"american\"  \n",
      "18       \"12969 ventura blvd.\"     \"los angeles\"        \"french\"  \n",
      "19          \"617 s. olive st.\"     \"los angeles\"       \"italian\"  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df_1 = pd.read_csv('https://query.data.world/s/vv3snq28bp0TJq2ggCdxGOghEQKPZo')\n",
    "df_2 = pd.read_csv('https://query.data.world/s/9wVKjNT0yiRc3YbVJaiI8a6HGl2d74')\n",
    "df_3 = df_1.merge(df_2,on=\"unique_id\",how=\"inner\")#Type your code here.\n",
    "print(df_3.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Operations on multiple dataframes\n",
    "Description\n",
    "Given three data frames containing the number of gold, silver, and bronze Olympic medals won by some countries, \n",
    "determine the total number of medals won by each country. \n",
    "\n",
    "Note: All three data frames don’t have all the same countries. So, ensure you use the ‘fill_value’ argument (set it to zero),\n",
    " to avoid getting NaN values. Also, ensure you sort the final data frame,\n",
    " according to the total medal count in descending order. Make sure that the results are in integers. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Medals\n",
       "Country        \n",
       "USA          72\n",
       "France       53\n",
       "UK           27\n",
       "Russia       25\n",
       "Germany      20"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Defining the three dataframes indicating the gold, silver, and bronze medal counts\n",
    "# of different countries\n",
    "gold = pd.DataFrame({'Country': ['USA', 'France', 'Russia'],\n",
    "                         'Medals': [15, 13, 9]}\n",
    "                    )\n",
    "silver = pd.DataFrame({'Country': ['USA', 'Germany', 'Russia'],\n",
    "                        'Medals': [29, 20, 16]}\n",
    "                    )\n",
    "bronze = pd.DataFrame({'Country': ['France', 'USA', 'UK'],\n",
    "                        'Medals': [40, 28, 27]}\n",
    "                    )\n",
    "\n",
    "\n",
    "outputdf = gold.merge(silver,on=\"Country\",how='outer').merge(bronze,on=\"Country\",how='outer').fillna(0)\n",
    "outputdf[\"Medals\"] = outputdf[\"Medals\"] + outputdf[\"Medals_x\"] + outputdf[\"Medals_y\"]\n",
    "finaldf = outputdf.sort_values('Medals',ascending = False)[[\"Country\",\"Medals\"]].set_index(\"Country\").astype('Int64')\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dataframe Append\n",
    "Description\n",
    "Append two datasets df_1 and df_2, and print the combined dataframe.\n",
    "\n",
    "Execution Time Limit \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name                     address             city  \\\n",
      "0  arnie morton's of chicago   \"435 s. la cienega blvd.\"    \"los angeles\"   \n",
      "1                 art's deli       \"12224 ventura blvd.\"    \"studio city\"   \n",
      "2              bel-air hotel      \"701 stone canyon rd.\"        \"bel air\"   \n",
      "3                 cafe bizou       \"14016 ventura blvd.\"   \"sherman oaks\"   \n",
      "4                  campanile       \"624 s. la brea ave.\"    \"los angeles\"   \n",
      "\n",
      "            cuisine unique_id name_2 address_2 city_2 cuisine_2  \n",
      "0     \"steakhouses\"       '0'    NaN       NaN    NaN       NaN  \n",
      "1           \"delis\"       '1'    NaN       NaN    NaN       NaN  \n",
      "2     \"californian\"       '2'    NaN       NaN    NaN       NaN  \n",
      "3   \"french bistro\"       '3'    NaN       NaN    NaN       NaN  \n",
      "4     \"californian\"       '4'    NaN       NaN    NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Suppressing warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df_1 = pd.read_csv('https://query.data.world/s/vv3snq28bp0TJq2ggCdxGOghEQKPZo')\n",
    "df_2 = pd.read_csv('https://query.data.world/s/9wVKjNT0yiRc3YbVJaiI8a6HGl2d74')\n",
    "df_3 = pd.concat([df_1,df_2],axis=0)#Type your code here.\n",
    "print(df_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dataframe Pivot Table\n",
    "Description\n",
    "Group the data 'df' by 'month' and 'day' and find the mean value for column 'rain' and 'wind' using the pivot table command. \"\"\"\n",
    "#df.pivot(columns='grouping_variable_col', values='value_to_aggregate', index='grouping_variable_row')\n",
    "#df.pivot_table(values, index, aggfunc={'value_1': np.mean,'value_2': [min, max, np.mean]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               rain      wind\n",
      "month day                    \n",
      "apr   fri  0.000000  3.100000\n",
      "      mon  0.000000  3.100000\n",
      "      sat  0.000000  4.500000\n",
      "      sun  0.000000  5.666667\n",
      "      thu  0.000000  5.800000\n",
      "      wed  0.000000  2.700000\n",
      "aug   fri  0.066667  4.766667\n",
      "      mon  0.000000  2.873333\n",
      "      sat  0.000000  4.310345\n",
      "      sun  0.025000  4.417500\n",
      "      thu  0.000000  3.503846\n",
      "      tue  0.300000  4.567857\n",
      "      wed  0.000000  3.520000\n",
      "dec   fri  0.000000  4.900000\n",
      "      mon  0.000000  8.500000\n",
      "      sun  0.000000  8.500000\n",
      "      thu  0.000000  4.900000\n",
      "      tue  0.000000  8.500000\n",
      "      wed  0.000000  8.000000\n",
      "feb   fri  0.000000  4.820000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df = pd.read_csv('https://query.data.world/s/vBDCsoHCytUSLKkLvq851k2b8JOCkF')\n",
    "df_1 = df.pivot_table(index=['month','day'],values=['rain','wind'],aggfunc=np.mean)#Type your code here. \n",
    "#df_1 = pd.pivot_table(df, values=['rain', 'wind'], index=['month', 'day'], aggfunc='mean')\n",
    "print(df_1.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Series Sub-setting\\nDescription\\nGiven a Pandas series and a value 'n', write a program to create a subset of the series whose value is greater than 'n'.\\n\\n\\n\\nInput: The first line contains a 1D list that will be converted to a Pandas series, and the second line contains an integer 'n'.\\n\\nOutput: Rows of the series whose value is less than n\\n\\n\\n\\nSample Input 1: [0, 1,2,3,4,5,6,7,8,9,10]\\n\\n6\\n\\nSample Output 1: \\n\\n0  0\\n\\n1  1\\n\\n2  2\\n\\n3  3\\n\\n4  4\\n\\n5  5\\n\\nSample Input 2: [8, 1,14,0,7,5,6,7,13,9,10]\\n\\n5\\n\\nSample Output 2: \\n\\n1  1\\n\\n3  0  \""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" **Pandas Coding Questions - I** \"\"\"\n",
    "\n",
    "\"\"\" Series Sub-setting\n",
    "Description\n",
    "Given a Pandas series and a value 'n', write a program to create a subset of the series whose value is greater than 'n'.\n",
    "\n",
    "\n",
    "\n",
    "Input: The first line contains a 1D list that will be converted to a Pandas series, and the second line contains an integer 'n'.\n",
    "\n",
    "Output: Rows of the series whose value is less than n\n",
    "\n",
    "\n",
    "\n",
    "Sample Input 1: [0, 1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "6\n",
    "\n",
    "Sample Output 1: \n",
    "\n",
    "0  0\n",
    "\n",
    "1  1\n",
    "\n",
    "2  2\n",
    "\n",
    "3  3\n",
    "\n",
    "4  4\n",
    "\n",
    "5  5\n",
    "\n",
    "Sample Input 2: [8, 1,14,0,7,5,6,7,13,9,10]\n",
    "\n",
    "5\n",
    "\n",
    "Sample Output 2: \n",
    "\n",
    "1  1\n",
    "\n",
    "3  0  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1\n",
       "3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "#input has been taken for you\n",
    "inp_list=ast.literal_eval(input())\n",
    "n=int(input())\n",
    "s = pd.Series(inp_list)\n",
    "#write your code here\n",
    "print(s[s<n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Description\n",
    "Given two Pandas series, s1 and s2, write a program to print the elements of s1 that are not present in s2.\n",
    "\n",
    "Input: The first line has a 1D list containing elements of the first series, s1 and the second line has another 1D list containing elements of the second series, s2.\n",
    "\n",
    "Output: Rows of the series whose value.\n",
    "\n",
    "Sample Input 1: [1, 2, 3, 4, 5]\n",
    "\n",
    "[2, 4, 6, 8, 10]\n",
    "\n",
    "Sample Output 1: \n",
    "\n",
    "0  1\n",
    "\n",
    "2  3\n",
    "\n",
    "4  5\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Series 1 and 2 have elements 2 and 4 in common. Hence, the elements that belong to s1 but not s2 are 1, 3 and 5.\n",
    " The output is in pandas series format containing the index of the elements also. \n",
    "\n",
    "Sample Input 2: [8, 1,14,0,7,5,6,7,13,9,10]\n",
    "\n",
    "[0, 1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "Sample Output 2: \n",
    "\n",
    "2  14\n",
    "\n",
    "8  13 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    14\n",
      "8    13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "# input has been taken for you\n",
    "inp_list1=  ast.literal_eval(input())\n",
    "inp_list2=  ast.literal_eval(input())\n",
    "s1 = pd.Series(inp_list1)\n",
    "s2 = pd.Series(inp_list2)\n",
    "\n",
    "# Write your code here\n",
    "print(s1[~s1.isin(s2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Description\n",
    "You have been given a dataset called 'heart'. Here are its first few rows:\n",
    "\n",
    "As you can see, the column names are all lowercase. \n",
    "Your task is to capitalize the first character of every column present in it such that your dataframe looks like the following:\n",
    "\n",
    "You just need to write the code for capitalizing; you need not print anything as the print statement has already been provided in the stub. \"\"\"\n",
    "\"\"\"https://stackoverflow.com/questions/31269216/applying-uppercase-to-a-column-in-pandas-dataframe\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Sex', 'Cp', 'Trestbps', 'Chol', 'Fbs', 'Restecg', 'Thalach',\n",
      "       'Exang', 'Oldpeak', 'Slope', 'Ca', 'Thal', 'Target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Importing the pandas package\n",
    "import pandas as pd\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# Reading the dataframe\n",
    "df = pd.read_csv('https://media-doselect.s3.amazonaws.com/generic/XWvQjYY4LZWdxLvPWOj2pPwn/heart.csv')\n",
    "\n",
    "# Write your code here\n",
    "df.columns = map(lambda x: str(x).capitalize(),df.columns)\n",
    "\n",
    "# Printing the final columns. Do not edit this part.\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Description\n",
    "You've been given the pima_indian_diabetes dataset. Here are its first few rows:\n",
    "Notice the BMI and Diabetes column. You need to find the BMI which is most likely to cause Diabetes. \n",
    "First round the BMI to an integer value and return which BMI has the most risk of diabetes based on the 0, 1 diabetes values provided in the dataframe.\n",
    "\n",
    "Expected Output: Just print a single integer denoting the value of the required BMI. \n",
    "(Please only output an integer value. For example, if the output is 30.0 please convert it to int and output 30.).  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "# Import the Pandas package\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# Reading the input dataframe\n",
    "pima = pd.read_csv('https://media-doselect.s3.amazonaws.com/generic/pLZK3n22ezVwAG2XOYW5qEx7V/pima_indian_diabetes.csv')\n",
    "pima['BMI']=pima['BMI'].apply(lambda x : int(x))\n",
    "pimadf=pima[pima['Diabetes']==1]\n",
    "pimadf1= pimadf['BMI'].median()\n",
    "print(np.int64(pimadf1))\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" You're given a movies dataframe which contains quite a few aspects of some movies from 1916-2016. Here are the first few rows of the dataframe.\n",
    "There are a lot of columns that aren't visible. But you might have noticed straight away that there are quite a few missing values in the data frame. Two columns for instance, 'aspect_ratio' and 'facenumber_in_poster' also have a few missing values(NaN). Now, replace the missing values with the 'median' value of the respective columns and print the null value count for both.\n",
    "\n",
    "\n",
    "\n",
    "Expected Output: First print the number of missing values in both of these columns, then output the median in both the columns and then impute the missing values with the respective medians and print the count of missing values again. Store all of these in a dictionary format like the following:\n",
    "\n",
    "\n",
    "\n",
    "{'aspect_ratio_mv': 431, 'facenumber_in_poster_mv': 97}\n",
    "\n",
    "{'aspect_ratio_median: 1.44, 'facenumber_in_poster': 2.0}\n",
    "\n",
    "{'aspect_ratio_final': 0, 'facenumber_in_poster_final': 0}\n",
    "\n",
    "\n",
    "\n",
    "The code for the same has been provided in the stub; you just need to complete these dictionaries.\n",
    "\n",
    "\n",
    "\n",
    "Note: You don't need to use any print statement. The print statements have already been written; you just need to complete the dictionaries provided in the stub. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 329]\n",
      "[1.0, 2.35]\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Importing the pandas package\n",
    "import pandas as pd \n",
    "\n",
    "# Reading the movies dataframe\n",
    "movies = pd.read_csv('movie_data.csv')\n",
    "\n",
    "# Your aim is to complete the following three print statements after all the colons\n",
    "\n",
    "mv = {'aspect_ratio_mv': movies['aspect_ratio'].isnull().sum(), 'facenumber_in_poster_mv': movies['facenumber_in_poster'].isnull().sum() }\n",
    "median = {'aspect_ratio_median': movies['aspect_ratio'].median(), 'facenumber_in_poster_median': movies['facenumber_in_poster'].median()}\n",
    "movies['aspect_ratio']=movies['aspect_ratio'].fillna(median['aspect_ratio_median'])\n",
    "movies['facenumber_in_poster']=movies['facenumber_in_poster'].fillna(median['facenumber_in_poster_median'])\n",
    "final = {'aspect_ratio_final':movies['aspect_ratio'].isnull().sum() , 'facenumber_in_poster_final':movies['facenumber_in_poster'].isnull().sum() }\n",
    "\n",
    "# Printing the values in the three dictionaries. Please do not edit this part\n",
    "print(sorted(mv.values()))\n",
    "print(sorted(median.values()))\n",
    "print(sorted(final.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Removing Missing Values\n",
    "Description\n",
    "Consider the movie dataset again. Here are the first few rows of the same:\n",
    "\n",
    "Now, while you imputed missing values in the last question, there are a few columns for which imputing the missing values won't be wise and it's better just to drop them. \n",
    "\n",
    "There are two columns 'actor_1_facebook_likes' and 'actor_2_facebook_likes' which have quite a few missing values but since you have less data points,\n",
    "you don't want to drop many of them. For a hypothetical analysis that you're conducting, it will be okay if one of them has a missing value but you can't afford to have both missing values. So your aim here is to find the indices of the rows in which both of these columns have missing values simultaneously.\n",
    "\n",
    "Expected Output:\n",
    "- First print the indices of the rows where both these columns have missing values. The print statement has been provided in the stub. \n",
    "You just need to fill it. \n",
    "- After you have printed the above indices, drop these particular rows and print the number of retained rows in the dataframe.\n",
    "\n",
    "A sample output would look like the following:\n",
    "[389, 1019, 1178, 3400, 4012]\n",
    "4847\n",
    "\n",
    "Here, the list in the first line indicates a sample list which indicates the indices of the rows where both of the columns have missing values.\n",
    "And the second line represents the number of rows remaining in the dataframe after you have dropped the above rows. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4502, 4519, 4720, 4837, 4945, 4946, 4990]\n",
      "5036\n"
     ]
    }
   ],
   "source": [
    "# Importing the pandas package\n",
    "import pandas as pd \n",
    "import requests\n",
    "import io\n",
    "c = requests.get('https://media-doselect.s3.amazonaws.com/generic/ZY9xWvEzMB7NEoW08r52L8j2O/movie_data (1).csv')\n",
    "s = c.content\n",
    "\n",
    "# Reading the dataframe\n",
    "movies = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "# Print out the indices of the rows in which both these columns have missing values\n",
    "# as a list\n",
    "print(list( movies[(movies['actor_1_facebook_likes'].isnull()) & (movies['actor_1_facebook_likes'].isnull())].index.values ))\n",
    "dropindex= list( movies[(movies['actor_1_facebook_likes'].isnull()) & (movies['actor_1_facebook_likes'].isnull())].index.values)\n",
    "# Write your code for dropping these particular rows here\n",
    "movies.drop(index=dropindex,axis=0,inplace=True) \n",
    "\n",
    "# Print the number of remaining rows\n",
    "print(movies.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This time you've a fully cleaned movie dataset. The first few rows of the dataset are shown below:\n",
    "You're a producer looking to make a blockbuster movie. \n",
    "There will primarily be three lead roles in your movie and you wish to cast the most popular actors for it.\n",
    "Now, since you don't want to take a risk, you will cast a trio which has already acted in together in a movie before. \n",
    "The metric that you've chosen to check the popularity is the Facebook likes of each of these actors.\n",
    "\n",
    "The dataframe has three columns to help you out for the same, viz. 'actor_1_facebook_likes', 'actor_2_facebook_likes',\n",
    " and 'actor_3_facebook_likes'. Your objective is to find the trio which has the most number of Facebook likes combined.\n",
    "But there is a small condition which is that none of the three actors' Facebook likes should be less than half of the other two. For example, the following is a valid combo:\n",
    "actor_1_facebook_likes: 70000\n",
    "actor_2_facebook_likes: 40000\n",
    "actor_3_facebook_likes: 50000\n",
    "\n",
    "But the below one is not:\n",
    "actor_1_facebook_likes: 70000\n",
    "actor_2_facebook_likes: 40000\n",
    "actor_3_facebook_likes: 30000\n",
    "\n",
    "since in this case, actor_3_facebook_likes is 30000, which is less than half of actor_1_facebook_likes.\n",
    "\n",
    "Expected Output: Find out the most popular trio and print them as a list sorted in alphabetical order. For example:\n",
    "['Brad Pitt', 'Jake Gyllenhaal' 'Meryl Streep'] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCH Pounder', 'Joel David Moore', 'Wes Studi']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Reading the movies file\n",
    "#movies = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "movies=pd.read_csv('movies_final (2).csv', sep='\\t')\n",
    " # Write your code here\n",
    "movies[\"likesum\"] = movies[\"actor_1_facebook_likes\"] + movies[\"actor_2_facebook_likes\"] + movies[\"actor_3_facebook_likes\"]\n",
    "df=movies[(movies[\"actor_1_facebook_likes\"] > movies[\"actor_2_facebook_likes\"]/2)&(movies[\"actor_1_facebook_likes\"] > movies[\"actor_3_facebook_likes\"]/2)&(movies[\"actor_2_facebook_likes\"] > movies[\"actor_1_facebook_likes\"]/2)&(movies[\"actor_2_facebook_likes\"] > movies[\"actor_3_facebook_likes\"]/2)&(movies[\"actor_3_facebook_likes\"] > movies[\"actor_1_facebook_likes\"]/2)&(movies[\"actor_3_facebook_likes\"] > movies[\"actor_2_facebook_likes\"]/2)]\n",
    "df = df.sort_values(by=\"likesum\",ascending=False)\n",
    "fin = dict(df.loc[0,[\"actor_1_name\",\"actor_2_name\",\"actor_3_name\"]])\n",
    "list(fin.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor_1_name</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_3_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50 Cent</th>\n",
       "      <th>Bill Duke</th>\n",
       "      <th>Marc John Jefferies</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaliyah</th>\n",
       "      <th>Lena Olin</th>\n",
       "      <th>Bruce Spence</th>\n",
       "      <td>775.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aasif Mandvi</th>\n",
       "      <th>Dequina Moore</th>\n",
       "      <th>Jordan Carlos</th>\n",
       "      <td>346.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Abbie Cornish</th>\n",
       "      <th>Gabourey Sidibe</th>\n",
       "      <th>Michael Stuhlbarg</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul Schneider</th>\n",
       "      <th>Samuel Roukin</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zooey Deschanel</th>\n",
       "      <th>Rip Torn</th>\n",
       "      <th>Kelly Preston</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Will Ferrell</th>\n",
       "      <th>Dallas Roberts</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zoë Kravitz</th>\n",
       "      <th>Jeremy Davies</th>\n",
       "      <th>Jim Gaffigan</th>\n",
       "      <td>943.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lily Rabe</th>\n",
       "      <th>Bob Balaban</th>\n",
       "      <td>943.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Óscar Jaenada</th>\n",
       "      <th>Brett Cullen</th>\n",
       "      <th>Sedona Legge</th>\n",
       "      <td>619.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3631 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     actor_1_facebook_likes  \\\n",
       "actor_1_name    actor_2_name    actor_3_name                                  \n",
       "50 Cent         Bill Duke       Marc John Jefferies                  1000.0   \n",
       "Aaliyah         Lena Olin       Bruce Spence                          775.0   \n",
       "Aasif Mandvi    Dequina Moore   Jordan Carlos                         346.0   \n",
       "Abbie Cornish   Gabourey Sidibe Michael Stuhlbarg                    2000.0   \n",
       "                Paul Schneider  Samuel Roukin                        2000.0   \n",
       "...                                                                     ...   \n",
       "Zooey Deschanel Rip Torn        Kelly Preston                       11000.0   \n",
       "                Will Ferrell    Dallas Roberts                      11000.0   \n",
       "Zoë Kravitz     Jeremy Davies   Jim Gaffigan                          943.0   \n",
       "                Lily Rabe       Bob Balaban                           943.0   \n",
       "Óscar Jaenada   Brett Cullen    Sedona Legge                          619.0   \n",
       "\n",
       "                                                     actor_2_facebook_likes  \\\n",
       "actor_1_name    actor_2_name    actor_3_name                                  \n",
       "50 Cent         Bill Duke       Marc John Jefferies                  1000.0   \n",
       "Aaliyah         Lena Olin       Bruce Spence                          541.0   \n",
       "Aasif Mandvi    Dequina Moore   Jordan Carlos                          41.0   \n",
       "Abbie Cornish   Gabourey Sidibe Michael Stuhlbarg                     906.0   \n",
       "                Paul Schneider  Samuel Roukin                         552.0   \n",
       "...                                                                     ...   \n",
       "Zooey Deschanel Rip Torn        Kelly Preston                         826.0   \n",
       "                Will Ferrell    Dallas Roberts                       8000.0   \n",
       "Zoë Kravitz     Jeremy Davies   Jim Gaffigan                          769.0   \n",
       "                Lily Rabe       Bob Balaban                           763.0   \n",
       "Óscar Jaenada   Brett Cullen    Sedona Legge                          350.0   \n",
       "\n",
       "                                                     actor_3_facebook_likes  \n",
       "actor_1_name    actor_2_name    actor_3_name                                 \n",
       "50 Cent         Bill Duke       Marc John Jefferies                   441.0  \n",
       "Aaliyah         Lena Olin       Bruce Spence                          531.0  \n",
       "Aasif Mandvi    Dequina Moore   Jordan Carlos                          31.0  \n",
       "Abbie Cornish   Gabourey Sidibe Michael Stuhlbarg                     816.0  \n",
       "                Paul Schneider  Samuel Roukin                         179.0  \n",
       "...                                                                     ...  \n",
       "Zooey Deschanel Rip Torn        Kelly Preston                         742.0  \n",
       "                Will Ferrell    Dallas Roberts                        405.0  \n",
       "Zoë Kravitz     Jeremy Davies   Jim Gaffigan                          472.0  \n",
       "                Lily Rabe       Bob Balaban                           559.0  \n",
       "Óscar Jaenada   Brett Cullen    Sedona Legge                            2.0  \n",
       "\n",
       "[3631 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Reading the movies file\n",
    "movies=pd.read_csv('movies_final (2).csv', sep='\\t')\n",
    "\n",
    "# Group the dataframe using the actor names as indices and facebook likes as values\n",
    "group = movies.pivot_table(values = ['actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes'],\n",
    "                           index = ['actor_1_name', 'actor_2_name', 'actor_3_name'], aggfunc='sum')\n",
    "                           \n",
    "# Create a new column 'Total likes' which will contain the sum of likes of all three actors \n",
    "group['Total likes'] = group['actor_1_facebook_likes'] + group['actor_2_facebook_likes'] + group['actor_3_facebook_likes']\n",
    "\n",
    "# Sort the dataframe using the 'Total likes' column\n",
    "group.sort_values(by=['Total likes'], inplace=True, ascending = False)\n",
    "\n",
    "# Reset the index of the grouped dataframe so you can access the indices as columns easily\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "# Initialise the value of a variable 'j' to 0. This variable will be used to keep\n",
    "# a track of the rows during the loop iteration\n",
    "j = 0\n",
    "\n",
    "# Run a loop through the length of the column 'Total likes'\n",
    "for i in group['Total likes']:\n",
    "# Sort the facebook likes of three actors and store them in a variable 'temp'    \n",
    "    temp = sorted([group.loc[j,'actor_1_facebook_likes'], group.loc[j,'actor_2_facebook_likes'], group.loc[j,'actor_3_facebook_likes']])\n",
    "\n",
    "# Check if the smallest value in temp is greater than half the value of the other two\n",
    "# And also check if the middle value is greater than half the value of the max value\n",
    "    if temp[0] >= temp[1]/2 and temp[0] >= temp[2]/2 and temp[1] >= temp[2]/2:\n",
    "# If the above condition satisfies, print the correspoding actor names as a sorted list \n",
    "# and break the loop\n",
    "        print(sorted([group.loc[j, 'actor_1_name'], group.loc[j, 'actor_2_name'], group.loc[j, 'actor_3_name']]))\n",
    "        break\n",
    "# Keep incrementing the value of j with every loop interation    \n",
    "    j += 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
